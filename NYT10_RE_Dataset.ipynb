{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cleaned file found, cleaning now...\n",
      "Number of samples loaded: 172448\n",
      "Number of broken samples: 33\n",
      "Number of trainable samples: 172415\n",
      "   fb_mid_e1  fb_mid_e2         e1_name         e2_name relation  \\\n",
      "0  m.01l443l   m.04t_bj    dave_holland  barry_altschul       NA   \n",
      "1  m.01l443l   m.04t_bj    dave_holland  barry_altschul       NA   \n",
      "2   m.04t_bj  m.01l443l  barry_altschul    dave_holland       NA   \n",
      "3   m.04t_bj  m.01l443l  barry_altschul    dave_holland       NA   \n",
      "4   m.0frkwp   m.04mh_g            ruth     little_neck       NA   \n",
      "\n",
      "                                            sentence  \n",
      "0  the occasion was suitably exceptional : a reun...  \n",
      "1  tonight he brings his energies and expertise t...  \n",
      "2  the occasion was suitably exceptional : a reun...  \n",
      "3  tonight he brings his energies and expertise t...  \n",
      "4              shapiro -- ruth of little_neck , ny .  \n",
      "{'NA': 0, '/location/neighborhood/neighborhood_of': 1, '/location/fr_region/capital': 2, '/location/cn_province/capital': 3, '/location/in_state/administrative_capital': 4, '/base/locations/countries/states_provinces_within': 5, '/business/company/founders': 6, '/location/country/languages_spoken': 7, '/people/person/place_of_birth': 8, '/people/deceased_person/place_of_death': 9, '/location/it_region/capital': 10, '/people/family/members': 11, '/location/us_state/capital': 12, '/location/us_county/county_seat': 13, '/people/profession/people_with_this_profession': 14, '/location/br_state/capital': 15, '/location/in_state/legislative_capital': 16, '/sports/sports_team/location': 17, '/people/person/religion': 18, '/location/in_state/judicial_capital': 19, '/business/company_advisor/companies_advised': 20, '/people/family/country': 21, '/time/event/locations': 22, '/business/company/place_founded': 23, '/location/administrative_division/country': 24, '/people/ethnicity/included_in_group': 25, '/location/mx_state/capital': 26, '/location/province/capital': 27, '/people/person/nationality': 28, '/business/person/company': 29, '/business/shopping_center_owner/shopping_centers_owned': 30, '/business/company/advisors': 31, '/business/shopping_center/owner': 32, '/people/person/ethnicity': 33, '/people/deceased_person/place_of_burial': 34, '/people/ethnicity/geographic_distribution': 35, '/people/person/place_lived': 36, '/business/company/major_shareholders': 37, '/broadcast/producer/location': 38, '/broadcast/content/location': 39, '/business/business_location/parent_company': 40, '/location/jp_prefecture/capital': 41, '/film/film/featured_film_locations': 42, '/people/place_of_interment/interred_here': 43, '/location/de_state/capital': 44, '/people/person/profession': 45, '/business/company/locations': 46, '/location/country/capital': 47, '/location/location/contains': 48, '/location/country/administrative_divisions': 49, '/people/person/children': 50, '/film/film_location/featured_in_films': 51, '/film/film_festival/location': 52, '/people/ethnicity/includes_groups': 53, '/sports/sports_team_location/teams': 54, '/people/ethnicity/people': 55, '/business/company_shareholder/major_shareholder_of': 56, '/business/company/industry': 57}\n"
     ]
    }
   ],
   "source": [
    "class NYT10Dataset(Dataset):\n",
    "    \"\"\"NYT10 dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, sentence_file, relation2id_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sentence_file (string): Path to the txt file with annotations.\n",
    "            relation2id_file (string): Path to txt file with mapping between relation and id\n",
    "        \"\"\"\n",
    "        self.clean_and_load_dataset(sentence_file)\n",
    "        \n",
    "        self.relation2id = {}\n",
    "        with open(relation2id_file, 'r') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=' ')\n",
    "            for row in reader:\n",
    "                self.relation2id[row[0]] = int(row[1])\n",
    "\n",
    "    def clean_and_load_dataset(self, sentence_file):\n",
    "        cleaned_sentence_file = sentence_file[:-4] + '_cleaned' + sentence_file[-4:]\n",
    "        if os.path.isfile(cleaned_sentence_file):\n",
    "            print('Cleaned file found! Loading now...')\n",
    "            self.sentences_frame = pd.read_csv(cleaned_sentence_file, sep='\\t', keep_default_na=False)\n",
    "            print('Number of trainable samples:', len(self.sentences_frame))\n",
    "            return\n",
    "\n",
    "        print('No cleaned file found, cleaning now...')\n",
    "\n",
    "        colnames = ['fb_mid_e1', 'fb_mid_e2', 'e1_name', 'e2_name', 'relation', 'sentence', 'end']\n",
    "        self.sentences_frame = pd.read_csv(sentence_file, \n",
    "                                           sep='\\t', \n",
    "                                           names=colnames,\n",
    "                                           keep_default_na=False)\n",
    "        self.sentences_frame.drop('end', axis=1, inplace=True)\n",
    "        print('Number of samples loaded:', len(self.sentences_frame))\n",
    "        \n",
    "        broken_samples = []\n",
    "        for i, (_, _, e1_name, e2_name, _, text) in self.sentences_frame.iterrows():\n",
    "            split_text = text.split(' ')\n",
    "            if e1_name not in split_text or e2_name not in split_text:\n",
    "                broken_samples.append(i)\n",
    "        print('Number of broken samples:', len(broken_samples))\n",
    "\n",
    "        self.sentences_frame.drop(broken_samples, axis=0, inplace=True)\n",
    "        print('Number of trainable samples:', len(self.sentences_frame))\n",
    "        \n",
    "        self.sentences_frame.to_csv(cleaned_sentence_file, sep='\\t', index=False)\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.sentences_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        _, _, e1_name, e2_name, relation, text = self.sentences_frame.iloc[idx]\n",
    "        text = text.split(' ')\n",
    "        e1_index = text.index(e1_name)\n",
    "        e2_index = text.index(e2_name)\n",
    "        lower, upper = sorted((e1_index, e2_index))\n",
    "\n",
    "        c1 = text[:lower]\n",
    "        c2 = text[lower+1:upper]\n",
    "        c3 = text[upper+1:]\n",
    "        return c1, c2, c3, self.relation2id[relation]\n",
    "\n",
    "sentences_dataset = NYT10Dataset('data/test.txt', 'data/relation2id.txt')\n",
    "print(sentences_dataset.sentences_frame.head())\n",
    "print(sentences_dataset.relation2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['rosemary',\n",
       "  'antonelle',\n",
       "  ',',\n",
       "  'the',\n",
       "  'daughter',\n",
       "  'of',\n",
       "  'teresa',\n",
       "  'l.',\n",
       "  'antonelle',\n",
       "  'and',\n",
       "  'patrick',\n",
       "  'antonelle',\n",
       "  'of'],\n",
       " [','],\n",
       " [',',\n",
       "  'was',\n",
       "  'married',\n",
       "  'yesterday',\n",
       "  'afternoon',\n",
       "  'to',\n",
       "  'lt.',\n",
       "  'thomas',\n",
       "  'joseph',\n",
       "  'quast',\n",
       "  ',',\n",
       "  'a',\n",
       "  'son',\n",
       "  'of',\n",
       "  'peggy',\n",
       "  'b.',\n",
       "  'quast',\n",
       "  'and',\n",
       "  'vice',\n",
       "  'adm.',\n",
       "  'philip',\n",
       "  'm.',\n",
       "  'quast',\n",
       "  'of',\n",
       "  'carmel',\n",
       "  ',',\n",
       "  'calif.',\n",
       "  '.'],\n",
       " 48)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "385469"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_dataset.sentences_frame[sentences_dataset.sentences_frame['relation'] == 'NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'weitzman',\n",
       "  'family',\n",
       "  'remember',\n",
       "  'with',\n",
       "  'great',\n",
       "  'affection',\n",
       "  'larry',\n",
       "  'plotkin',\n",
       "  ',',\n",
       "  'and',\n",
       "  'join',\n",
       "  'in',\n",
       "  'sorrow'],\n",
       " ['and',\n",
       "  'the',\n",
       "  'selwyns',\n",
       "  ',',\n",
       "  'and',\n",
       "  'in',\n",
       "  'particular',\n",
       "  ',',\n",
       "  'john',\n",
       "  ',',\n",
       "  'sarah',\n",
       "  'and'],\n",
       " ['.'],\n",
       " 0)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_dataset[55990]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sentence in sentences_dataset:\n",
    "    x = sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
